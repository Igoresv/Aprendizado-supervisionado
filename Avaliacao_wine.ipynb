{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UP0f1_vSeMLz"
      },
      "outputs": [],
      "source": [
        "# Import necessary packages\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from copy import deepcopy as cp\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    StratifiedKFold)\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    auc,\n",
        "    RocCurveDisplay\n",
        ")\n",
        "\n",
        "sns.set_style(\"ticks\")\n",
        "sns.set_context(\"paper\")\n",
        "\n",
        "random_state = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "penT1EJweML3",
        "outputId": "ba2776f2-479b-4b73-99fb-0dcbe73deb36"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-97f58e65e25e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/winequalityN.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/winequalityN.csv'"
          ]
        }
      ],
      "source": [
        "wines = pd.read_csv(\"data/winequalityN.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZC26r6meML4"
      },
      "outputs": [],
      "source": [
        "wines.isnull().sum().sort_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSguzF0aeML6"
      },
      "outputs": [],
      "source": [
        "wines.dropna(axis=0,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qDdMCNieML7"
      },
      "outputs": [],
      "source": [
        "vars = [\n",
        "   'fixed acidity',\n",
        "   'volatile acidity',\n",
        "   'citric acid',\n",
        "   'residual sugar',\n",
        "   'chlorides',\n",
        "   'free sulfur dioxide',\n",
        "   'total sulfur dioxide',\n",
        "   'density',\n",
        "   'pH',\n",
        "   'sulphates',\n",
        "   'alcohol'\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueX1yhJieML7"
      },
      "source": [
        "- **fixed acidity:** a maioria dos ácidos envolvidos com vinho (não evaporam prontamente)\n",
        "- **volatile acidity:** a quantidade de ácido acético no vinho, que em níveis muito altos pode levar a um gosto desagradável de vinagre\n",
        "- **volatile acidity:** a quantidade de ácido acético no vinho, que em níveis muito altos pode levar a um gosto desagradável de vinagre\n",
        "- **citric acid:** encontrado em pequenas quantidades, o ácido cítrico pode adicionar \"leveza\" e sabor aos vinhos\n",
        "- **residual sugar:** a quantidade de açúcar restante após a fermentação é interrompida, é raro encontrar vinhos com menos de 1 grama / litro e vinhos com mais de 45 gramas / litro são considerados doces\n",
        "- **chlorides:** a quantidade de sal no vinho free sulfur dioxide: a forma livre de SO2 existe em equilíbrio entre o SO2 molecular (como gás dissolvido) e o íon bissulfito; impede o crescimento microbiano e a oxidação do vinho\n",
        "- **total sulfur dioxide:** Quantidade de formas livres e encadernadas de S02; em baixas concentrações, o SO2 é quase indetectável no vinho, mas nas concentrações de SO2 acima de 50 ppm, o SO2 se torna evidente no nariz e no sabor do vinho.\n",
        "- **density:** a densidade do vinho é próxima a da água, dependendo do percentual de álcool e teor de açúcar\n",
        "- **pH:** descreve se o vinho é ácido ou básico numa escala de 0 (muito ácido) a 14 (muito básico); a maioria dos vinhos está entre 3-4 na escala de pH\n",
        "- **sulphates:** um aditivo de vinho que pode contribuir para os níveis de gás de dióxido de enxofre (S02), que age como um antimicrobiano e antioxidante\n",
        "- **alcohol:** o percentual de álcool no vinho"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0KQW7bheML_"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(data=wines,hue=\"type\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZI8k7qieMMA"
      },
      "source": [
        "______________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLaRyjqkeMMA"
      },
      "source": [
        "White Wines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOK9aQLMeMMB"
      },
      "outputs": [],
      "source": [
        "white_wines = wines[wines['type'] == \"white\"].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64ajGr-DeMMB"
      },
      "outputs": [],
      "source": [
        "#white_wines.dropna(axis=0,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJfsX9theMMC"
      },
      "outputs": [],
      "source": [
        "white_wines.reset_index(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfHPLaMpeMMD"
      },
      "source": [
        "Crie uma nova variável, chamada \"opinion\" que será uma variável categórica igual à 0, quando quality for menor e igual à 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJmEGoepeMME"
      },
      "outputs": [],
      "source": [
        "white_wines[\"opinion\"] = (white_wines.quality > 5).astype(int)\n",
        "white_wines[\"opinion\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbaymUNneMMF"
      },
      "outputs": [],
      "source": [
        "white_wines.isnull().sum().sort_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wqx876zeMMF"
      },
      "source": [
        "Descreva as variáveis presentes na base. Quais são as variáveis? Quais são os tipos de variáveis (discreta, categórica, contínua)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ctpL6MGeMMF"
      },
      "outputs": [],
      "source": [
        "white_wines.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tl9dbmJIeMMG"
      },
      "outputs": [],
      "source": [
        "white_wines.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ve-E1yJ_eMMG"
      },
      "outputs": [],
      "source": [
        "white_wines.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfeOFLdseMMG"
      },
      "source": [
        "____________________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezbsqfNheMMH"
      },
      "source": [
        "Quais são os tipos de variáveis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrEJLlsSeMMH"
      },
      "outputs": [],
      "source": [
        "types = [\n",
        "        (\"Type\", \"Categórica\"),\n",
        "        (\"Fixed_Acidity\", \"Discreta\"),\n",
        "        (\"Fixed_Acidity\", \"Discreta\"),\n",
        "        (\"Volatile_Acidity\", \"Contínua\"),\n",
        "        (\"Citric_Acid\", \"Contínua\"),\n",
        "        (\"Residual_Sugar\", \"Contínua\"),\n",
        "        (\"Chlorides\", \"Contínua\"),\n",
        "        (\"Free_Sulfur_Dioxide\", \"Discreta\"),\n",
        "        (\"Total_Sulfur_Dioxide\", \"Discreta\"),\n",
        "        (\"Density\", \"Contínua\"),\n",
        "        (\"pH\", \"Contínua\"),\n",
        "        (\"Sulphates\", \"Contínua\"),\n",
        "        (\"Alcohol\", \"Contínua\"),\n",
        "        (\"Quality\", \"Discreta\"),\n",
        "        (\"Opinion\", \"Categórica\")\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_h72dIkeMMI"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(types,columns=[\"Variável\",\"Tipo\"])\n",
        "df = df.set_index([\"Variável\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WddEOd4eMMI"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUuE5uTTeMMJ"
      },
      "source": [
        "Quais são as médias e desvios padrões"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szXIfkZXeMMJ"
      },
      "outputs": [],
      "source": [
        "white_wines.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYHJOskLeMMJ"
      },
      "outputs": [],
      "source": [
        "sns.set(font_scale=1.3,rc={\"figure.figsize\":(20,20)})\n",
        "eixo = white_wines.hist(bins=20, color=\"blue\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gmz5PBP5eMMK"
      },
      "outputs": [],
      "source": [
        "correlation = white_wines.corr()\n",
        "correlation\n",
        "sns.set(rc = {'figure.figsize':(14,9)})\n",
        "plot = sns.heatmap(correlation, annot = True, fmt=\".1f\", linewidths=1, linecolor='black')\n",
        "plot;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eT3z5VP2eMMK"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "sns.boxplot(data=white_wines,x=\"opinion\",y=\"quality\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SudIOwSDeMML"
      },
      "source": [
        "____________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTCivcTbeMML"
      },
      "source": [
        "Para criar um modelo de classificação eficaz, você pode seguir as seguintes etapas:\n",
        "\n",
        "Coleta e preparação dos dados: Inicie coletando os dados relevantes para o seu problema de classificação. Em seguida, verifique a qualidade dos dados, limpe-os, remova valores ausentes, normalize as características e trate quaisquer inconsistências ou valores atípicos.\n",
        "\n",
        "Análise exploratória dos dados: Realize uma análise exploratória dos dados para obter insights valiosos sobre as características, distribuições e relacionamentos dos dados. Visualize os dados usando gráficos, tabelas e estatísticas descritivas. Isso ajudará a entender melhor o problema, identificar padrões e determinar quais características podem ser mais relevantes para a classificação.\n",
        "\n",
        "Divisão dos dados em conjuntos de treinamento, validação e teste: Separe os dados em três conjuntos distintos: treinamento, validação e teste. O conjunto de treinamento será usado para treinar o modelo, o conjunto de validação ajudará a ajustar os hiperparâmetros do modelo e o conjunto de teste será usado para avaliar o desempenho final do modelo. A proporção típica é de 70-80% para treinamento, 10-15% para validação e 10-15% para teste, mas isso pode variar dependendo do tamanho do conjunto de dados disponível.\n",
        "\n",
        "Seleção de características: Se você tiver muitas características, pode ser útil realizar uma seleção de características para identificar as mais relevantes para o problema de classificação. Isso pode ser feito usando métodos estatísticos, como análise de correlação ou teste de significância, ou usando algoritmos de seleção de características, como a análise de componentes principais (PCA) ou a seleção baseada em árvores de decisão.\n",
        "\n",
        "Escolha do algoritmo de classificação: Com base no seu problema de classificação e nos dados disponíveis, escolha o algoritmo de classificação mais adequado. Alguns algoritmos comuns incluem árvores de decisão, regressão logística e SVM.\n",
        "\n",
        "Treinamento do modelo: Use o conjunto de treinamento para treinar o modelo selecionado. Isso envolve alimentar os dados ao algoritmo de classificação e ajustar os parâmetros internos do modelo para otimizar seu desempenho. Durante o treinamento, o modelo aprenderá a mapear as características dos dados para suas respectivas classes.\n",
        "\n",
        "Validação e ajuste de hiperparâmetros: Use o conjunto de validação para avaliar o desempenho do modelo e ajustar seus hiperparâmetros. Os hiperparâmetros são configurações que controlam o comportamento do algoritmo de classificação, como a profundidade máxima de uma árvore de decisão ou o tamanho do lote em uma rede neural. Experimente diferentes valores de hiperparâmetros e avalie seu impacto no desempenho do modelo usando métricas apropriadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Zsn-PexeMML"
      },
      "source": [
        "_______________________________________________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuBgvZ_ueMMM"
      },
      "outputs": [],
      "source": [
        "X = white_wines[vars]\n",
        "y = white_wines['opinion']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQljWy0eeMMM"
      },
      "outputs": [],
      "source": [
        "# Vamos dividir a base entre treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.values,\n",
        "                                                    y.values,\n",
        "                                                    test_size=0.2, # 20 % da base\n",
        "                                                    random_state=171,\n",
        "                                                    stratify=y)\n",
        "\n",
        "# Vamos criar a escala\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Vamos treinar!\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Vamos avaliar!!!\n",
        "\n",
        "y_prob = model.predict_proba(X_train_scaled)\n",
        "y_pred = model.predict(X_train_scaled)\n",
        "\n",
        "y_pred_test = model.predict(X_test_scaled)\n",
        "\n",
        "print(f\" F1-Score é {f1_score(y_train, y_pred):.2}\")\n",
        "print(f\" F1-Score é {f1_score(y_test, y_pred_test):.2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-BAPMK8eMMM"
      },
      "source": [
        "Treinando com K-Folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2N4Bo4FeMMM"
      },
      "outputs": [],
      "source": [
        "cv = StratifiedKFold(n_splits=10)\n",
        "\n",
        "\n",
        "f1_score_test_list = []\n",
        "model_list =[]\n",
        "accuracy_list = []\n",
        "precision_list = []\n",
        "recall_list = []\n",
        " \n",
        "for fold, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
        "    X_train = X.loc[train_idx, :].values\n",
        "    y_train = y[train_idx]\n",
        "    X_test = X.loc[test_idx, :].values\n",
        "    y_test = y[test_idx]\n",
        "\n",
        "    # Escala\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Treino\n",
        "    model = LogisticRegression()\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    y_prob = model.predict_proba(X_train_scaled)\n",
        "    y_pred = model.predict(X_train_scaled)\n",
        "\n",
        "    y_pred_test = model.predict(X_test_scaled)\n",
        "    print(f\"========================= FOLD {fold} ==========================\")\n",
        "    print(f\" F1-Score é {f1_score(y_train, y_pred):.2}\")\n",
        "    print(f\" F1-Score é {f1_score(y_test, y_pred_test):.2}\") \n",
        "    f1_score_test_list.append(f1_score(y_test, y_pred_test))\n",
        "    model_list.append(model)\n",
        "    accuracy_list.append(accuracy_score(y_test, y_pred_test))\n",
        "    precision_list.append(precision_score(y_test, y_pred_test))\n",
        "    recall_list.append(recall_score(y_test, y_pred_test))\n",
        "print()\n",
        "print()\n",
        "print(\"========================= Questão 4.b ==========================\")\n",
        "print(f\" F1-Score Médio é {np.mean(f1_score_test_list): .5} +- {np.std(f1_score_test_list): .2} \")\n",
        "print(f\" Acurácia Médio é {np.mean(accuracy_list): .5} +- {np.std(accuracy_list): .2} \")\n",
        "print(f\" Precisão Média é {np.mean(precision_list): .5} +- {np.std(precision_list): .2} \")\n",
        "print(f\" Sensibilidade/Recall Médio é {np.mean(recall_list): .5} +- {np.std(recall_list): .2} \")\n",
        "best_model = model_list[np.argmax(f1_score_test_list)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_toWsiXyeMMa"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test,y_pred_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBGEdLHteMMb"
      },
      "source": [
        "______________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vs8ZZ87DeMMb"
      },
      "source": [
        "# Curva Roc - Código"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qc2pxUmWeMMc"
      },
      "outputs": [],
      "source": [
        "def logit_train(X, y, test_size : float = 0.2, random_state=42, stratify=None, **logit_kwargs):\n",
        "    \"\"\"\n",
        "    Method for training a model using logit regression.\n",
        "    \"\"\"\n",
        "    random.seed(random_state) # \"GLOBAL\"/ LOCAL\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                        y,\n",
        "                                                        test_size=test_size,\n",
        "                                                        random_state=random_state, # LOCAL\n",
        "                                                        stratify=stratify)\n",
        "    scaler = StandardScaler() # LOCAL\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    model = LogisticRegression(**logit_kwargs, random_state=random_state)\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    return {\n",
        "        'model': model,\n",
        "        'scaler': scaler,\n",
        "        'X_train': X_train,\n",
        "        'X_train_scaled': X_train_scaled,\n",
        "        'X_test': X_test,\n",
        "        'X_test_scaled': X_test_scaled,\n",
        "        'y_train': y_train,\n",
        "        'y_test': y_test\n",
        "    }\n",
        "\n",
        "class LogitTrainResults:\n",
        "    def __init__(self, results):\n",
        "        self.model = results['model']\n",
        "        self.scaler = results['scaler']\n",
        "        self.X_train = results['X_train']\n",
        "        self.X_train_scaled = results['X_train_scaled']\n",
        "        self.X_test = results['X_test']\n",
        "        self.X_test_scaled = results['X_test_scaled']\n",
        "        self.y_train = results['y_train']\n",
        "        self.y_test = results['y_test']\n",
        "\n",
        "    def accuracy_train(self):\n",
        "        y_pred = self.model.predict(self.X_train_scaled)\n",
        "        return accuracy_score(self.y_train, y_pred)\n",
        "\n",
        "    def accuracy_test(self):\n",
        "        y_pred = self.model.predict(self.X_test_scaled)\n",
        "        return accuracy_score(self.y_test, y_pred)\n",
        "\n",
        "    def plot_roc(self, X, y, estimator_name : str = \"treino\", **kwargs):\n",
        "        y_hat = self.model.predict_proba(X)\n",
        "        fpr, tpr, thresholds = roc_curve(y, y_hat[:, 1], pos_label=1)\n",
        "        auc_score = auc(fpr, tpr)\n",
        "\n",
        "        return RocCurveDisplay(fpr=fpr,\n",
        "                               tpr=tpr,\n",
        "                               roc_auc=auc_score,\n",
        "                               estimator_name = estimator_name).plot(**kwargs)\n",
        "\n",
        "    def plot_roc_train(self, **kwargs):\n",
        "        self.plot_roc(self.X_train_scaled, self.y_train, estimator_name=\"treino\", **kwargs)\n",
        "\n",
        "    def plot_roc_test(self, **kwargs):\n",
        "        self.plot_roc(self.X_test_scaled, self.y_test, estimator_name=\"teste\", **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGXWEZ0QeMMv"
      },
      "outputs": [],
      "source": [
        "X = white_wines[vars]\n",
        "y = white_wines['opinion']\n",
        "stratify = y\n",
        "random_state = 42\n",
        "test_size = 0.1\n",
        "\n",
        "X_train_cv, X_test, y_train_cv, y_test = train_test_split(X.values,\n",
        "                                                          y.values,\n",
        "                                                          test_size=test_size,\n",
        "                                                          random_state=random_state,\n",
        "                                                          stratify=stratify)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_UC_6e9eMMx"
      },
      "outputs": [],
      "source": [
        "def interpolation(fpr, tpr):\n",
        "    interp_fpr = np.linspace(0, 1, 100)\n",
        "    interp_tpr = np.interp(interp_fpr, fpr, tpr)\n",
        "    interp_tpr[0] = 0.\n",
        "    return interp_fpr, interp_tpr\n",
        "\n",
        "def train_cv(model, cv):\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(14, 14))\n",
        "    fprs_list = []\n",
        "    tprs_list = []\n",
        "    auc_list  = []\n",
        "    scaler_list = []\n",
        "    for fold, (train, val) in enumerate(cv.split(X_train_cv, y_train_cv)):\n",
        "        X_train = X_train_cv[train, :]\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        scaler_list.append(scaler)\n",
        "        y_train = y_train_cv[train]\n",
        "        X_val = X_train_cv[val, :]\n",
        "        X_val_scaled = scaler.transform(X_val)\n",
        "        y_val = y_train_cv[val]\n",
        "\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        viz = RocCurveDisplay.from_estimator(\n",
        "            model,\n",
        "            X_val_scaled,\n",
        "            y_val,\n",
        "            ax = ax,\n",
        "            alpha=0.3,\n",
        "            lw=1\n",
        "        )\n",
        "        interp_fpr, interp_tpr = interpolation(viz.fpr, viz.tpr)\n",
        "        fprs_list.append(interp_fpr)\n",
        "        tprs_list.append(interp_tpr)\n",
        "        auc_list.append(viz.roc_auc) \n",
        "\n",
        "    mean_fpr = np.mean(fprs_list, axis=0)\n",
        "    mean_tpr = np.mean(tprs_list, axis=0)\n",
        "    mean_auc = np.mean(auc_list)\n",
        "    std_auc = np.std(auc_list)\n",
        "\n",
        "    ax.plot(\n",
        "        mean_fpr,\n",
        "        mean_tpr,\n",
        "        color='blue',\n",
        "        lw=2,\n",
        "        label=r\"Mean ROC (AUC = %.2f $\\pm$ %.2f)\" %(mean_auc, std_auc)\n",
        "    )\n",
        "\n",
        "\n",
        "    ax.plot(np.linspace(0, 1, 100),\n",
        "            np.linspace(0, 1, 100),\n",
        "            color='g',\n",
        "            ls=\":\",\n",
        "            lw=0.5)\n",
        "    ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T02Mnr_UeMMx"
      },
      "source": [
        "Curva ROC Regressão Logística"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nH93GfXYeMMy"
      },
      "outputs": [],
      "source": [
        "\n",
        "cv = StratifiedKFold(n_splits=10)\n",
        "model_1 = LogisticRegression(max_iter=10000, random_state=random_state)\n",
        "train_cv(model_1, cv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlG_4vgreMMz"
      },
      "source": [
        "______________________________________________________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXJ_o3vJeMMz"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import (\n",
        "    DecisionTreeClassifier, \n",
        "    plot_tree\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ParBJqoCeMM0"
      },
      "outputs": [],
      "source": [
        "StratifiedKFold(n_splits=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8K6WrkQeMM1"
      },
      "outputs": [],
      "source": [
        "X_train_cv, X_test, y_train_cv, y_test = train_test_split(X.values,\n",
        "                                                          y.values,\n",
        "                                                          test_size=0.2, # 20 % da base\n",
        "                                                          random_state=42,\n",
        "                                                          stratify=y)\n",
        "\n",
        "def train(X, y, model_klass, model_kwargs = {}):\n",
        "    cv = StratifiedKFold(n_splits=10)\n",
        "    \n",
        "    f1_score_val_list = []\n",
        "    f1_score_train_list = []\n",
        "    model_list =[]\n",
        "    scaler_list = []\n",
        "    model_list =[]\n",
        "    accuracy_list = []\n",
        "    precision_list = []\n",
        "    recall_list = []\n",
        "    \n",
        "    # Validação cruzada só em Training Data\n",
        "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
        "        X_train = X[train_idx, :]\n",
        "        y_train = y[train_idx]\n",
        "        X_val = X[val_idx, :]\n",
        "        y_val = y[val_idx]\n",
        "\n",
        "        # Escala\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "        scaler_list.append(scaler)\n",
        "\n",
        "        # Treino\n",
        "        model = model_klass(**model_kwargs)\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        y_pred = model.predict(X_train_scaled)\n",
        "\n",
        "        y_pred_val = model.predict(X_val_scaled)\n",
        "        print(f\"========================= FOLD {fold} ==========================\")\n",
        "        print(f\"Meu resultado para treino de F1-Score é {f1_score(y_train, y_pred):.2}\")\n",
        "        print(f\"Meu resultado para validação de F1-Score é {f1_score(y_val, y_pred_val):.2}\")\n",
        "        print(f\"Meu resultado para validação de Recall é {recall_score(y_train, y_pred):.2}\") \n",
        "        print(f\"Meu resultado para validação de Acurácia é {accuracy_score(y_train, y_pred):.2}\")\n",
        "        print(f\"Meu resultado para validação de Precisão é {precision_score(y_train, y_pred):.2}\")\n",
        "        \n",
        "        f1_score_val_list.append(f1_score(y_val, y_pred_val))\n",
        "        f1_score_train_list.append(f1_score(y_train, y_pred))\n",
        "        accuracy_list.append(accuracy_score(y_train, y_pred))\n",
        "        precision_list.append(precision_score(y_train, y_pred))\n",
        "        recall_list.append(recall_score(y_train, y_pred))\n",
        "        model_list.append(model)\n",
        "\n",
        "    print()\n",
        "    print(\"-------------------------------------------------------------------------------------\")\n",
        "    print()\n",
        "    print(f\" F1-Score Médio de treino é {np.mean(f1_score_train_list): .5} +- {np.std(f1_score_train_list): .2} \")\n",
        "    print(f\" F1-Score Médio de validação é {np.mean(f1_score_val_list): .5} +- {np.std(f1_score_val_list): .2} \")\n",
        "    print(f\" Recall Médio é {np.mean(recall_list): .5} +- {np.std(recall_list): .2} \")\n",
        "    print(f\" Acurácia Média é {np.mean(accuracy_list): .5} +- {np.std(accuracy_list): .2} \")\n",
        "    print(f\" Precisão Média é {np.mean(precision_list): .5} +- {np.std(precision_list): .2} \")\n",
        "\n",
        "    print()\n",
        "\n",
        "    best_model_idx = np.argmax(f1_score_val_list)\n",
        "    print(f\"Meu melhor fold é: {best_model_idx} \")\n",
        "    best_model = model_list[best_model_idx]\n",
        "\n",
        "    # Fazer a inferência em Test Data\n",
        "    best_scaler = scaler_list[best_model_idx]\n",
        "    X_test_scaled = best_scaler.transform(X_test)\n",
        "    y_pred_test = model.predict(X_test_scaled)\n",
        "\n",
        "    print()\n",
        "    print(f\" F1-Score para o conjunto de teste é: {f1_score(y_test, y_pred_test):.2} \")\n",
        "    return best_model, best_scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-46eUwjUeMM2"
      },
      "outputs": [],
      "source": [
        "tree_model = train(X_train_cv, y_train_cv, DecisionTreeClassifier, model_kwargs={'min_samples_leaf': 50})[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5TNJzuHeMM3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(1, 1, figsize=(60, 60))\n",
        "plot_tree(tree_model, filled=True);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc2eFubreMM4"
      },
      "source": [
        "Curva ROC Árvore de Decisão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1e_SSRWCeMM4"
      },
      "outputs": [],
      "source": [
        "train_cv(tree_model, cv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqDrpFpxeMM5"
      },
      "source": [
        "__________________________________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15I15_q0eMM9"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "SVM = train(X_train_cv, y_train_cv, SVC, model_kwargs={'gamma': 2, 'C': 1, 'kernel': 'rbf'})[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbpLDUESeMM_"
      },
      "source": [
        "Curva ROC SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT6maBGLeMNA"
      },
      "outputs": [],
      "source": [
        "train_cv(SVM, cv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wDqZPKNeMND"
      },
      "source": [
        "____________________________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OS0WqtkheMNH"
      },
      "outputs": [],
      "source": [
        "train_cv(model_1, cv), train_cv(tree_model, cv), train_cv(SVM, cv);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUT2kaTQeMNI"
      },
      "source": [
        "_______________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5SQ4Z_XeMNI"
      },
      "source": [
        "Comparando os resultados dos três modelos disponíveis (Árvore de Decisão, Regressão Logística e SVM), podemos observar o seguinte:\n",
        "\n",
        "**1. Árvore de Decisão:**\n",
        "\n",
        "- F1-Score Médio de treino: 0.84 +- 0.0043\n",
        "- F1-Score Médio de validação: 0.82 +- 0.015\n",
        "- Recall Médio: 0.86 +- 0.015\n",
        "- Acurácia Média: 0.79 +- 0.0049\n",
        "- Precisão Média: 0.83 +- 0.0091\n",
        "- AUC Médio: 0.81 +- 0.02\n",
        "\n",
        "**2. Regressão Logística:**\n",
        "\n",
        "- F1-Score Médio: 0.82 +- 0.032\n",
        "- Acurácia Média: 0.74 +- 0.042\n",
        "- Precisão Média: 0.77 +- 0.035\n",
        "- Recall Médio: 0.87 +- 0.06\n",
        "- AUC Médio: 0.80 +- 0.02\n",
        "\n",
        "**3. SVM:**\n",
        "\n",
        "- F1-Score Médio de treino: 0.99 +- 0.00051\n",
        "- F1-Score Médio de validação: 0.85 +- 0.0063\n",
        "- Recall Médio: 1.0 +- 0.0011\n",
        "- Acurácia Média: 0.99 +- 0.00068\n",
        "- Precisão Média: 0.99 +- 0.00067\n",
        "- AUC Médio: 0.87 +- 0.01\n",
        "\n",
        "Considerando os resultados apresentados, **o modelo de SVM demonstra um desempenho geral superior em comparação com os outros modelos**. Ele possui altas pontuações em todas as métricas avaliadas, incluindo F1-Score, Recall, Acurácia, Precisão e AUC. Além disso, o modelo de SVM também apresenta menor variação nas métricas, o que indica maior consistência em seu desempenho."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn0zL6RseMNJ"
      },
      "source": [
        "Com base no resultado do melhor modelo, podemos ainda fazer a seguinte análise:\n",
        "\n",
        "**1. F1-Score Médio:** O F1-Score é uma métrica que combina precisão e recall, fornecendo uma medida geral do desempenho do modelo. Um valor de F1-Score médio de treino de 0.99 indica que o modelo teve um desempenho muito bom na classificação dos dados de treinamento. No entanto, é importante observar que a diferença de 0.00051 indica que pode haver alguma variação no desempenho do modelo em diferentes execuções.\n",
        "\n",
        "**2. F1-Score Médio de Validação:** O F1-Score médio de validação de 0.85 indica o desempenho médio do modelo ao classificar dados não vistos durante o treinamento. Embora seja um valor decente, é notável que o desempenho do modelo em validação é menor do que o desempenho em treinamento. A diferença de 0.0063 sugere alguma variação no desempenho do modelo em diferentes conjuntos de validação.\n",
        "\n",
        "**3. Recall Médio:** O recall mede a proporção de instâncias positivas que foram corretamente identificadas pelo modelo. Um valor de recall médio de 1.0 indica que o modelo conseguiu recuperar corretamente todas as instâncias positivas durante o treinamento, o que é um bom resultado.\n",
        "\n",
        "**4. Acurácia Média:** A acurácia mede a proporção de instâncias corretamente classificadas pelo modelo em relação ao total de instâncias. Um valor de acurácia média de 0.99 indica que o modelo teve um desempenho muito bom na classificação geral dos dados de treinamento.\n",
        "\n",
        "**5. Precisão Média:** A precisão mede a proporção de instâncias classificadas como positivas que são realmente positivas. Um valor de precisão média de 0.99 indica que o modelo teve um desempenho muito bom em evitar falsos positivos durante o treinamento.\n",
        "\n",
        "**6. Curva ROC:** A média AUC (Área Sob a Curva ROC) de 0.87 com uma variação de +/- 0.01 indica que o modelo de SVM tem um desempenho razoável na classificação dos dados. Uma AUC de 0.87 indica que o modelo possui uma boa capacidade de distinguir entre classes positivas e negativas. \n",
        "\n",
        "Em geral, o modelo de SVM apresentou um desempenho impressionante nos dados de treinamento, com alta precisão, recall, acurácia e F1-Score. No entanto, é importante considerar a diferença observada nos resultados de validação, o que pode indicar uma certa variação no desempenho em diferentes conjuntos de dados não vistos durante o treinamento. Portanto, é recomendável avaliar o desempenho do modelo em um conjunto de teste independente para obter uma avaliação mais precisa de sua capacidade de generalização."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs2ZJjoqeMNL"
      },
      "source": [
        "_________________________________________________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3miqooUeMNM"
      },
      "outputs": [],
      "source": [
        "red_wines = wines[wines['type'] == \"red\"].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUkr8C7CeMNN"
      },
      "outputs": [],
      "source": [
        "red_wines.dropna(axis=0,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOhe52VHeMNN"
      },
      "outputs": [],
      "source": [
        "red_wines.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odRYgB8OeMNO"
      },
      "outputs": [],
      "source": [
        "red_wines.isnull().sum().sort_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4rQ2Y1WeMNP"
      },
      "source": [
        "Criando uma nova variável, chamada \"opinion\" que será uma variável categórica igual à 0, quando quality for menor e igual à 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_SfiNlKeMNP"
      },
      "outputs": [],
      "source": [
        "number_of_wines = red_wines.shape[0]\n",
        "red_wines['opinion'] =  np.zeros((number_of_wines, 1))\n",
        "red_wines.loc[red_wines.quality > 5, \"opinion\"] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIhhJ9F5eMNQ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4LMU2D-eMNQ"
      },
      "outputs": [],
      "source": [
        "red_wines.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIARQxmceMNR"
      },
      "outputs": [],
      "source": [
        "X_red = red_wines[vars]\n",
        "y_red = red_wines['opinion']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOPAIsP7eMNS"
      },
      "outputs": [],
      "source": [
        "best_white_model, best_white_scaler = train(X_train_cv, y_train_cv, SVC, model_kwargs={'gamma': 2, 'C': 1, 'kernel': 'rbf'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nw77a4AyeMNT"
      },
      "outputs": [],
      "source": [
        "X_red_scaled = best_white_scaler.transform(X_red)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AilN5prheMNU"
      },
      "outputs": [],
      "source": [
        "y_red_pred = best_white_model.predict(X_red_scaled)\n",
        "y_red_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OP3aabkveMNU"
      },
      "outputs": [],
      "source": [
        "print(f\"O F1-Score é {f1_score(y_red, y_red_pred):.5}\")\n",
        "print(f\"O Recall é {recall_score(y_red, y_red_pred):.5}\") \n",
        "print(f\"A Acurácia é {accuracy_score(y_red, y_red_pred):.5}\")\n",
        "print(f\"A Precisão é {precision_score(y_red, y_red_pred):.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-Cq2hWVeMNV"
      },
      "source": [
        "_________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx8j6VI8eMNW"
      },
      "source": [
        "### Com a escolha do melhor modelo, use os dados de vinho tinto, presentes na base original e faça a inferência. Utilize o mesmo critério utilizado com os vinhos brancos, para comparar o desempenho do modelo. Ele funciona da mesma forma para essa nova base? Justifique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx9dJAgGeMNW"
      },
      "source": [
        "Funciona bem diferente, e isso pode ser explicado pelo fato do modelo ser treinado com os dados dos vinhos brancos e agora tentar prever com os dados dos tintos, com características bem diferentes.\n",
        "\n",
        "**1.  Resultados do Vinho Tinto:**\n",
        "\n",
        "- O F1-Score é 0.69668\n",
        "- O Recall é 1.0\n",
        "- A Acurácia é 0.53484\n",
        "- A Precisão é 0.53455\n",
        "\n",
        "**2. Resultados do Vinho Branco:**\n",
        "\n",
        "\n",
        "-  F1-Score Médio de treino é  1.0 +-  0.0012 \n",
        "-  F1-Score Médio de validação é  0.79 +-  0.02 \n",
        "-  Recall Médio é  1.0 +-  0.0015 \n",
        "-  Acurácia Média é  0.99 +-  0.0013 \n",
        "-  Precisão Média é  0.99 +-  0.0018 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S-urumGeMNY"
      },
      "source": [
        "_______________________________________________"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}